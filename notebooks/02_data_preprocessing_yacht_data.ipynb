{
  "cells": [
    {
      "cell_type": "markdown",
      "id": "2636cb1b-f7ef-40a8-9c11-cb764dbdb2e5",
      "metadata": {
        "id": "2636cb1b-f7ef-40a8-9c11-cb764dbdb2e5"
      },
      "source": [
        " **02 ‚Äì DATA PREPROCESSING**\n",
        "\n",
        "The purpose of this notebook is to clean and prepare the raw data so it‚Äôs suitable for analysis and modeling. This step includes loading the dataset, checking for issues like missing values or duplicates, and making sure the data types are correct. It also covers encoding categorical variables, scaling features, and preparing the train/test split."
      ]
    },
    {
      "cell_type": "markdown",
      "id": "e13c99a5-488a-490a-9910-4cb52abad1f8",
      "metadata": {
        "id": "e13c99a5-488a-490a-9910-4cb52abad1f8"
      },
      "source": [
        "**1. Load the Datasets**\n",
        "   \n",
        "This step loads all CSV files from the data/raw/ folder into a dictionary of pandas DataFrames, using the filenames (without .csv) as keys. The code handles potential encoding and mixed-type issues by specifying encoding (ISO-8859-1) and using dtype=str. This approach ensures easy access to and inspection of multiple datasets."
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "KsZ_JgrHC714",
        "outputId": "755865d2-669e-4560-d992-d1d4aaa2a792"
      },
      "id": "KsZ_JgrHC714",
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "id": "577de4e1-8c62-40b6-9d93-ab0c405ac994",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "577de4e1-8c62-40b6-9d93-ab0c405ac994",
        "outputId": "da30b413-4231-4e1b-8109-e3c7fe023523"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Loaded named_anchorages_v1_20191205 with shape (166508, 10)\n",
            "Loaded CVP_loitering_202411 with shape (684, 14)\n",
            "Loaded named_anchorages_v1_20181108 with shape (119748, 7)\n",
            "Loaded Weather-for-Boating-Activities with shape (1060, 6)\n",
            "Loaded CVP_ports_202411 with shape (1410, 14)\n",
            "Loaded boat_data with shape (9888, 10)\n",
            "Loaded CVP_encounters_202411 with shape (348, 14)\n",
            "Loaded sar_vessel_detections_pipev20231026_202410 with shape (268681, 10)\n",
            "Loaded named_anchorages_v2_20201104 with shape (166515, 10)\n",
            "Loaded boat_dataset with shape (10344, 38)\n",
            "Loaded Boats_No_Price_dataset with shape (936, 26)\n",
            "Loaded named_anchorages_v2_20221206 with shape (166482, 10)\n",
            "Loaded sar_vessel_detections_pipev3_202411 with shape (248247, 10)\n",
            "Loaded sar_vessel_detections_pipev3_202412 with shape (239081, 10)\n",
            "\n",
            "First file preview:        s2id                  lat                 lon     label sublabel  \\\n",
            "0  3e4e429b   26.914042109356018   52.22031972443178   SHARJAH      NaN   \n",
            "1  1a575de7  -7.7159917314685496   11.72455952408813  BLOCK 17      NaN   \n",
            "2  3fcf5295    29.64207745041846   48.69670549586832  KAZ IRAQ      NaN   \n",
            "3  3fcf52bf   29.644147649617455  48.701872570021656  KAZ IRAQ      NaN   \n",
            "4  3fcf52bd   29.639744433742802  48.701768589783754  UMM QASR      NaN   \n",
            "\n",
            "      label_source iso3 distance_from_shore_m         drift_radius at_dock  \n",
            "0  top_destination  IRN                 63000  0.05632213051303668   FALSE  \n",
            "1  top_destination  AGO                134000   0.1111107365900863   FALSE  \n",
            "2  top_destination  KWT                 33000  0.16258325996472844   FALSE  \n",
            "3  top_destination  KWT                 33000  0.16162288669261704   FALSE  \n",
            "4  top_destination  KWT                 33000   0.1499641855732754   FALSE  \n"
          ]
        }
      ],
      "source": [
        "import os\n",
        "import glob\n",
        "import pandas as pd\n",
        "import warnings\n",
        "from pandas.errors import DtypeWarning\n",
        "\n",
        "# Suppress DtypeWarning\n",
        "warnings.simplefilter(action='ignore', category=DtypeWarning)\n",
        "\n",
        "# Path to the raw data folder\n",
        "raw_data_path = '/content/drive/MyDrive/yacht-data-insights/data/raw/'\n",
        "\n",
        "# Get a list of all CSV files in the folder\n",
        "csv_files = glob.glob(os.path.join(raw_data_path, '*.csv'))\n",
        "\n",
        "# Create a dictionary of DataFrames with the filename (without extension) as the key\n",
        "dataframes = {}\n",
        "\n",
        "for file in csv_files:\n",
        "    name = os.path.splitext(os.path.basename(file))[0]  # filename without path or extension\n",
        "    try:\n",
        "        # Read the CSV with dtype=str to avoid mixed type issues\n",
        "        df = pd.read_csv(file, encoding='ISO-8859-1', dtype=str, low_memory=False)\n",
        "        dataframes[name] = df\n",
        "        print(f\"Loaded {name} with shape {df.shape}\")\n",
        "    except Exception as e:\n",
        "        print(f\"Error loading {name}: {e}\")\n",
        "\n",
        "# Optionally, check the first file to confirm\n",
        "if csv_files:\n",
        "    first_file = csv_files[0]\n",
        "    preview_df = pd.read_csv(first_file, encoding='ISO-8859-1', dtype=str, low_memory=False)\n",
        "    print(f\"\\nFirst file preview: {preview_df.head()}\")\n",
        "else:\n",
        "    print(\"No CSV files found.\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "cce4ae79-199d-4407-8a7c-7ff765c2c3b4",
      "metadata": {
        "id": "cce4ae79-199d-4407-8a7c-7ff765c2c3b4"
      },
      "source": [
        "**2. Initial Checks: Data Types, Missing Values, and Duplicates**\n",
        "\n",
        "This step involves checking the data types to ensure each column is correctly formatted. It also includes identifying any missing values by counting them for each column. Additionally, duplicate rows are checked for any repetitions. These checks help identify common data issues that need to be addressed before further analysis."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "id": "becd6270-e50d-4b55-aa5b-0d196057956f",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "becd6270-e50d-4b55-aa5b-0d196057956f",
        "outputId": "bc5be2d8-e5cb-4eda-d2dd-47d4a0e1a3b5"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "üîç Initial checks for: named_anchorages_v1_20191205\n",
            "\n",
            "üìÑ Dataset Info:\n",
            "<class 'pandas.core.frame.DataFrame'>\n",
            "RangeIndex: 166508 entries, 0 to 166507\n",
            "Data columns (total 10 columns):\n",
            " #   Column                 Non-Null Count   Dtype \n",
            "---  ------                 --------------   ----- \n",
            " 0   s2id                   166508 non-null  object\n",
            " 1   lat                    166508 non-null  object\n",
            " 2   lon                    166508 non-null  object\n",
            " 3   label                  166502 non-null  object\n",
            " 4   sublabel               5586 non-null    object\n",
            " 5   label_source           166508 non-null  object\n",
            " 6   iso3                   166501 non-null  object\n",
            " 7   distance_from_shore_m  166483 non-null  object\n",
            " 8   drift_radius           166346 non-null  object\n",
            " 9   at_dock                166507 non-null  object\n",
            "dtypes: object(10)\n",
            "memory usage: 12.7+ MB\n",
            "None\n",
            "\n",
            "‚ùì Missing Values per Column:\n",
            "s2id                          0\n",
            "lat                           0\n",
            "lon                           0\n",
            "label                         6\n",
            "sublabel                 160922\n",
            "label_source                  0\n",
            "iso3                          7\n",
            "distance_from_shore_m        25\n",
            "drift_radius                162\n",
            "at_dock                       1\n",
            "dtype: int64\n",
            "\n",
            "üîÅ Number of Duplicate Rows:\n",
            "0\n",
            "\n",
            "üîç Initial checks for: CVP_loitering_202411\n",
            "\n",
            "üìÑ Dataset Info:\n",
            "<class 'pandas.core.frame.DataFrame'>\n",
            "RangeIndex: 684 entries, 0 to 683\n",
            "Data columns (total 14 columns):\n",
            " #   Column           Non-Null Count  Dtype \n",
            "---  ------           --------------  ----- \n",
            " 0   event_id         684 non-null    object\n",
            " 1   event_type       684 non-null    object\n",
            " 2   vessel_id        684 non-null    object\n",
            " 3   event_start      684 non-null    object\n",
            " 4   event_end        684 non-null    object\n",
            " 5   lat_mean         684 non-null    object\n",
            " 6   lon_mean         684 non-null    object\n",
            " 7   lat_min          684 non-null    object\n",
            " 8   lat_max          684 non-null    object\n",
            " 9   lon_min          684 non-null    object\n",
            " 10  lon_max          684 non-null    object\n",
            " 11  event_info       684 non-null    object\n",
            " 12  event_vessels    684 non-null    object\n",
            " 13  event_geography  684 non-null    object\n",
            "dtypes: object(14)\n",
            "memory usage: 74.9+ KB\n",
            "None\n",
            "\n",
            "‚ùì Missing Values per Column:\n",
            "event_id           0\n",
            "event_type         0\n",
            "vessel_id          0\n",
            "event_start        0\n",
            "event_end          0\n",
            "lat_mean           0\n",
            "lon_mean           0\n",
            "lat_min            0\n",
            "lat_max            0\n",
            "lon_min            0\n",
            "lon_max            0\n",
            "event_info         0\n",
            "event_vessels      0\n",
            "event_geography    0\n",
            "dtype: int64\n",
            "\n",
            "üîÅ Number of Duplicate Rows:\n",
            "0\n",
            "\n",
            "üîç Initial checks for: named_anchorages_v1_20181108\n",
            "\n",
            "üìÑ Dataset Info:\n",
            "<class 'pandas.core.frame.DataFrame'>\n",
            "RangeIndex: 119748 entries, 0 to 119747\n",
            "Data columns (total 7 columns):\n",
            " #   Column           Non-Null Count   Dtype \n",
            "---  ------           --------------   ----- \n",
            " 0   s2id             119748 non-null  object\n",
            " 1   label            119746 non-null  object\n",
            " 2   sublabel         4158 non-null    object\n",
            " 3   iso3             119741 non-null  object\n",
            " 4   lat              119748 non-null  object\n",
            " 5   lon              119748 non-null  object\n",
            " 6   anchorage_group  119748 non-null  object\n",
            "dtypes: object(7)\n",
            "memory usage: 6.4+ MB\n",
            "None\n",
            "\n",
            "‚ùì Missing Values per Column:\n",
            "s2id                    0\n",
            "label                   2\n",
            "sublabel           115590\n",
            "iso3                    7\n",
            "lat                     0\n",
            "lon                     0\n",
            "anchorage_group         0\n",
            "dtype: int64\n",
            "\n",
            "üîÅ Number of Duplicate Rows:\n",
            "0\n",
            "\n",
            "üîç Initial checks for: Weather-for-Boating-Activities\n",
            "\n",
            "üìÑ Dataset Info:\n",
            "<class 'pandas.core.frame.DataFrame'>\n",
            "RangeIndex: 1060 entries, 0 to 1059\n",
            "Data columns (total 6 columns):\n",
            " #   Column                    Non-Null Count  Dtype \n",
            "---  ------                    --------------  ----- \n",
            " 0   √Ø¬ª¬øWind Speed             1060 non-null   object\n",
            " 1   Wave Height               1060 non-null   object\n",
            " 2   Weather                   1060 non-null   object\n",
            " 3   Day of the Week           1060 non-null   object\n",
            " 4   Boat Technical Condition  1060 non-null   object\n",
            " 5   Decision                  1060 non-null   object\n",
            "dtypes: object(6)\n",
            "memory usage: 49.8+ KB\n",
            "None\n",
            "\n",
            "‚ùì Missing Values per Column:\n",
            "√Ø¬ª¬øWind Speed               0\n",
            "Wave Height                 0\n",
            "Weather                     0\n",
            "Day of the Week             0\n",
            "Boat Technical Condition    0\n",
            "Decision                    0\n",
            "dtype: int64\n",
            "\n",
            "üîÅ Number of Duplicate Rows:\n",
            "935\n",
            "\n",
            "üîç Initial checks for: CVP_ports_202411\n",
            "\n",
            "üìÑ Dataset Info:\n",
            "<class 'pandas.core.frame.DataFrame'>\n",
            "RangeIndex: 1410 entries, 0 to 1409\n",
            "Data columns (total 14 columns):\n",
            " #   Column           Non-Null Count  Dtype \n",
            "---  ------           --------------  ----- \n",
            " 0   event_id         1410 non-null   object\n",
            " 1   event_type       1410 non-null   object\n",
            " 2   vessel_id        1410 non-null   object\n",
            " 3   event_start      1410 non-null   object\n",
            " 4   event_end        1410 non-null   object\n",
            " 5   lat_mean         1410 non-null   object\n",
            " 6   lon_mean         1410 non-null   object\n",
            " 7   lat_min          1410 non-null   object\n",
            " 8   lat_max          1410 non-null   object\n",
            " 9   lon_min          1410 non-null   object\n",
            " 10  lon_max          1410 non-null   object\n",
            " 11  event_info       1410 non-null   object\n",
            " 12  event_vessels    1410 non-null   object\n",
            " 13  event_geography  1410 non-null   object\n",
            "dtypes: object(14)\n",
            "memory usage: 154.3+ KB\n",
            "None\n",
            "\n",
            "‚ùì Missing Values per Column:\n",
            "event_id           0\n",
            "event_type         0\n",
            "vessel_id          0\n",
            "event_start        0\n",
            "event_end          0\n",
            "lat_mean           0\n",
            "lon_mean           0\n",
            "lat_min            0\n",
            "lat_max            0\n",
            "lon_min            0\n",
            "lon_max            0\n",
            "event_info         0\n",
            "event_vessels      0\n",
            "event_geography    0\n",
            "dtype: int64\n",
            "\n",
            "üîÅ Number of Duplicate Rows:\n",
            "0\n",
            "\n",
            "üîç Initial checks for: boat_data\n",
            "\n",
            "üìÑ Dataset Info:\n",
            "<class 'pandas.core.frame.DataFrame'>\n",
            "RangeIndex: 9888 entries, 0 to 9887\n",
            "Data columns (total 10 columns):\n",
            " #   Column                       Non-Null Count  Dtype \n",
            "---  ------                       --------------  ----- \n",
            " 0   Price                        9888 non-null   object\n",
            " 1   Boat Type                    9888 non-null   object\n",
            " 2   Manufacturer                 8550 non-null   object\n",
            " 3   Type                         9882 non-null   object\n",
            " 4   Year Built                   9888 non-null   object\n",
            " 5   Length                       9879 non-null   object\n",
            " 6   Width                        9832 non-null   object\n",
            " 7   Material                     8139 non-null   object\n",
            " 8   Location                     9852 non-null   object\n",
            " 9   Number of views last 7 days  9888 non-null   object\n",
            "dtypes: object(10)\n",
            "memory usage: 772.6+ KB\n",
            "None\n",
            "\n",
            "‚ùì Missing Values per Column:\n",
            "Price                             0\n",
            "Boat Type                         0\n",
            "Manufacturer                   1338\n",
            "Type                              6\n",
            "Year Built                        0\n",
            "Length                            9\n",
            "Width                            56\n",
            "Material                       1749\n",
            "Location                         36\n",
            "Number of views last 7 days       0\n",
            "dtype: int64\n",
            "\n",
            "üîÅ Number of Duplicate Rows:\n",
            "0\n",
            "\n",
            "üîç Initial checks for: CVP_encounters_202411\n",
            "\n",
            "üìÑ Dataset Info:\n",
            "<class 'pandas.core.frame.DataFrame'>\n",
            "RangeIndex: 348 entries, 0 to 347\n",
            "Data columns (total 14 columns):\n",
            " #   Column           Non-Null Count  Dtype \n",
            "---  ------           --------------  ----- \n",
            " 0   event_id         348 non-null    object\n",
            " 1   event_type       348 non-null    object\n",
            " 2   vessel_id        348 non-null    object\n",
            " 3   event_start      348 non-null    object\n",
            " 4   event_end        348 non-null    object\n",
            " 5   lat_mean         348 non-null    object\n",
            " 6   lon_mean         348 non-null    object\n",
            " 7   lat_min          348 non-null    object\n",
            " 8   lat_max          348 non-null    object\n",
            " 9   lon_min          348 non-null    object\n",
            " 10  lon_max          348 non-null    object\n",
            " 11  event_info       348 non-null    object\n",
            " 12  event_vessels    348 non-null    object\n",
            " 13  event_geography  348 non-null    object\n",
            "dtypes: object(14)\n",
            "memory usage: 38.2+ KB\n",
            "None\n",
            "\n",
            "‚ùì Missing Values per Column:\n",
            "event_id           0\n",
            "event_type         0\n",
            "vessel_id          0\n",
            "event_start        0\n",
            "event_end          0\n",
            "lat_mean           0\n",
            "lon_mean           0\n",
            "lat_min            0\n",
            "lat_max            0\n",
            "lon_min            0\n",
            "lon_max            0\n",
            "event_info         0\n",
            "event_vessels      0\n",
            "event_geography    0\n",
            "dtype: int64\n",
            "\n",
            "üîÅ Number of Duplicate Rows:\n",
            "0\n",
            "\n",
            "üîç Initial checks for: sar_vessel_detections_pipev20231026_202410\n",
            "\n",
            "üìÑ Dataset Info:\n",
            "<class 'pandas.core.frame.DataFrame'>\n",
            "RangeIndex: 268681 entries, 0 to 268680\n",
            "Data columns (total 10 columns):\n",
            " #   Column            Non-Null Count   Dtype \n",
            "---  ------            --------------   ----- \n",
            " 0   scene_id          268681 non-null  object\n",
            " 1   timestamp         268681 non-null  object\n",
            " 2   lat               268681 non-null  object\n",
            " 3   lon               268681 non-null  object\n",
            " 4   presence_score    268681 non-null  object\n",
            " 5   length_m          268681 non-null  object\n",
            " 6   mmsi              211416 non-null  object\n",
            " 7   matching_score    268681 non-null  object\n",
            " 8   fishing_score     268680 non-null  object\n",
            " 9   matched_category  268681 non-null  object\n",
            "dtypes: object(10)\n",
            "memory usage: 20.5+ MB\n",
            "None\n",
            "\n",
            "‚ùì Missing Values per Column:\n",
            "scene_id                0\n",
            "timestamp               0\n",
            "lat                     0\n",
            "lon                     0\n",
            "presence_score          0\n",
            "length_m                0\n",
            "mmsi                57265\n",
            "matching_score          0\n",
            "fishing_score           1\n",
            "matched_category        0\n",
            "dtype: int64\n",
            "\n",
            "üîÅ Number of Duplicate Rows:\n",
            "0\n",
            "\n",
            "üîç Initial checks for: named_anchorages_v2_20201104\n",
            "\n",
            "üìÑ Dataset Info:\n",
            "<class 'pandas.core.frame.DataFrame'>\n",
            "RangeIndex: 166515 entries, 0 to 166514\n",
            "Data columns (total 10 columns):\n",
            " #   Column                 Non-Null Count   Dtype \n",
            "---  ------                 --------------   ----- \n",
            " 0   s2id                   166515 non-null  object\n",
            " 1   lat                    166515 non-null  object\n",
            " 2   lon                    166515 non-null  object\n",
            " 3   label                  166509 non-null  object\n",
            " 4   sublabel               5596 non-null    object\n",
            " 5   label_source           166515 non-null  object\n",
            " 6   iso3                   166508 non-null  object\n",
            " 7   distance_from_shore_m  166490 non-null  object\n",
            " 8   drift_radius           166346 non-null  object\n",
            " 9   at_dock                166480 non-null  object\n",
            "dtypes: object(10)\n",
            "memory usage: 12.7+ MB\n",
            "None\n",
            "\n",
            "‚ùì Missing Values per Column:\n",
            "s2id                          0\n",
            "lat                           0\n",
            "lon                           0\n",
            "label                         6\n",
            "sublabel                 160919\n",
            "label_source                  0\n",
            "iso3                          7\n",
            "distance_from_shore_m        25\n",
            "drift_radius                169\n",
            "at_dock                      35\n",
            "dtype: int64\n",
            "\n",
            "üîÅ Number of Duplicate Rows:\n",
            "0\n",
            "\n",
            "üîç Initial checks for: boat_dataset\n",
            "\n",
            "üìÑ Dataset Info:\n",
            "<class 'pandas.core.frame.DataFrame'>\n",
            "RangeIndex: 10344 entries, 0 to 10343\n",
            "Data columns (total 38 columns):\n",
            " #   Column                       Non-Null Count  Dtype \n",
            "---  ------                       --------------  ----- \n",
            " 0   Price                        10344 non-null  object\n",
            " 1   Category                     10344 non-null  object\n",
            " 2   Boat Type                    10344 non-null  object\n",
            " 3   Manufacturer                 8954 non-null   object\n",
            " 4   Model                        10341 non-null  object\n",
            " 5   Boat name                    1313 non-null   object\n",
            " 6   Type                         10339 non-null  object\n",
            " 7   Year Built                   9777 non-null   object\n",
            " 8   Condition                    3375 non-null   object\n",
            " 9   Length                       10334 non-null  object\n",
            " 10  Width                        10281 non-null  object\n",
            " 11  Depth                        7234 non-null   object\n",
            " 12  Displacement                 5051 non-null   object\n",
            " 13  CE Design Category           782 non-null    object\n",
            " 14  Cert Number of People        3597 non-null   object\n",
            " 15  Number of Cabins             6475 non-null   object\n",
            " 16  Number of beds               6407 non-null   object\n",
            " 17  Hull Color                   3311 non-null   object\n",
            " 18  Number of Toilets            2156 non-null   object\n",
            " 19  Number of Bathrooms          463 non-null    object\n",
            " 20  Number of Showers            1941 non-null   object\n",
            " 21  Material                     8512 non-null   object\n",
            " 22  Fresh Water Cap              2118 non-null   object\n",
            " 23  Holding Tank                 819 non-null    object\n",
            " 24  Propulsion                   3291 non-null   object\n",
            " 25  Engine                       9535 non-null   object\n",
            " 26  Engine Performance           8063 non-null   object\n",
            " 27  Fuel Capacity                6814 non-null   object\n",
            " 28  Fuel Type                    8022 non-null   object\n",
            " 29  Engine Hours                 5133 non-null   object\n",
            " 30  Max Speed                    892 non-null    object\n",
            " 31  Cruising Speed               547 non-null    object\n",
            " 32  Location                     10301 non-null  object\n",
            " 33  Advertisement Date           870 non-null    object\n",
            " 34  Number of views last 7 days  9981 non-null   object\n",
            " 35  Comments                     7078 non-null   object\n",
            " 36  Additional Comments          2454 non-null   object\n",
            " 37  Equipment                    6174 non-null   object\n",
            "dtypes: object(38)\n",
            "memory usage: 3.0+ MB\n",
            "None\n",
            "\n",
            "‚ùì Missing Values per Column:\n",
            "Price                             0\n",
            "Category                          0\n",
            "Boat Type                         0\n",
            "Manufacturer                   1390\n",
            "Model                             3\n",
            "Boat name                      9031\n",
            "Type                              5\n",
            "Year Built                      567\n",
            "Condition                      6969\n",
            "Length                           10\n",
            "Width                            63\n",
            "Depth                          3110\n",
            "Displacement                   5293\n",
            "CE Design Category             9562\n",
            "Cert Number of People          6747\n",
            "Number of Cabins               3869\n",
            "Number of beds                 3937\n",
            "Hull Color                     7033\n",
            "Number of Toilets              8188\n",
            "Number of Bathrooms            9881\n",
            "Number of Showers              8403\n",
            "Material                       1832\n",
            "Fresh Water Cap                8226\n",
            "Holding Tank                   9525\n",
            "Propulsion                     7053\n",
            "Engine                          809\n",
            "Engine Performance             2281\n",
            "Fuel Capacity                  3530\n",
            "Fuel Type                      2322\n",
            "Engine Hours                   5211\n",
            "Max Speed                      9452\n",
            "Cruising Speed                 9797\n",
            "Location                         43\n",
            "Advertisement Date             9474\n",
            "Number of views last 7 days     363\n",
            "Comments                       3266\n",
            "Additional Comments            7890\n",
            "Equipment                      4170\n",
            "dtype: int64\n",
            "\n",
            "üîÅ Number of Duplicate Rows:\n",
            "1\n",
            "\n",
            "üîç Initial checks for: Boats_No_Price_dataset\n",
            "\n",
            "üìÑ Dataset Info:\n",
            "<class 'pandas.core.frame.DataFrame'>\n",
            "RangeIndex: 936 entries, 0 to 935\n",
            "Data columns (total 26 columns):\n",
            " #   Column          Non-Null Count  Dtype \n",
            "---  ------          --------------  ----- \n",
            " 0   Unnamed: 0      936 non-null    object\n",
            " 1   id              936 non-null    object\n",
            " 2   type            936 non-null    object\n",
            " 3   boatClass       936 non-null    object\n",
            " 4   make            936 non-null    object\n",
            " 5   model           936 non-null    object\n",
            " 6   year            936 non-null    object\n",
            " 7   condition       936 non-null    object\n",
            " 8   length_ft       936 non-null    object\n",
            " 9   beam_ft         885 non-null    object\n",
            " 10  dryWeight_lb    616 non-null    object\n",
            " 11  hullMaterial    936 non-null    object\n",
            " 12  fuelType        885 non-null    object\n",
            " 13  numEngines      936 non-null    object\n",
            " 14  totalHP         817 non-null    object\n",
            " 15  maxEngineYear   353 non-null    object\n",
            " 16  minEngineYear   350 non-null    object\n",
            " 17  engineCategory  705 non-null    object\n",
            " 18  price           0 non-null      object\n",
            " 19  sellerId        936 non-null    object\n",
            " 20  city            921 non-null    object\n",
            " 21  state           921 non-null    object\n",
            " 22  zip             855 non-null    object\n",
            " 23  created_date    936 non-null    object\n",
            " 24  created_month   936 non-null    object\n",
            " 25  created_year    936 non-null    object\n",
            "dtypes: object(26)\n",
            "memory usage: 190.3+ KB\n",
            "None\n",
            "\n",
            "‚ùì Missing Values per Column:\n",
            "Unnamed: 0          0\n",
            "id                  0\n",
            "type                0\n",
            "boatClass           0\n",
            "make                0\n",
            "model               0\n",
            "year                0\n",
            "condition           0\n",
            "length_ft           0\n",
            "beam_ft            51\n",
            "dryWeight_lb      320\n",
            "hullMaterial        0\n",
            "fuelType           51\n",
            "numEngines          0\n",
            "totalHP           119\n",
            "maxEngineYear     583\n",
            "minEngineYear     586\n",
            "engineCategory    231\n",
            "price             936\n",
            "sellerId            0\n",
            "city               15\n",
            "state              15\n",
            "zip                81\n",
            "created_date        0\n",
            "created_month       0\n",
            "created_year        0\n",
            "dtype: int64\n",
            "\n",
            "üîÅ Number of Duplicate Rows:\n",
            "0\n",
            "\n",
            "üîç Initial checks for: named_anchorages_v2_20221206\n",
            "\n",
            "üìÑ Dataset Info:\n",
            "<class 'pandas.core.frame.DataFrame'>\n",
            "RangeIndex: 166482 entries, 0 to 166481\n",
            "Data columns (total 10 columns):\n",
            " #   Column                 Non-Null Count   Dtype \n",
            "---  ------                 --------------   ----- \n",
            " 0   s2id                   166482 non-null  object\n",
            " 1   lat                    166482 non-null  object\n",
            " 2   lon                    166482 non-null  object\n",
            " 3   label                  166482 non-null  object\n",
            " 4   sublabel               160198 non-null  object\n",
            " 5   label_source           166482 non-null  object\n",
            " 6   iso3                   166482 non-null  object\n",
            " 7   distance_from_shore_m  166457 non-null  object\n",
            " 8   drift_radius           166329 non-null  object\n",
            " 9   dock                   166462 non-null  object\n",
            "dtypes: object(10)\n",
            "memory usage: 12.7+ MB\n",
            "None\n",
            "\n",
            "‚ùì Missing Values per Column:\n",
            "s2id                        0\n",
            "lat                         0\n",
            "lon                         0\n",
            "label                       0\n",
            "sublabel                 6284\n",
            "label_source                0\n",
            "iso3                        0\n",
            "distance_from_shore_m      25\n",
            "drift_radius              153\n",
            "dock                       20\n",
            "dtype: int64\n",
            "\n",
            "üîÅ Number of Duplicate Rows:\n",
            "0\n",
            "\n",
            "üîç Initial checks for: sar_vessel_detections_pipev3_202411\n",
            "\n",
            "üìÑ Dataset Info:\n",
            "<class 'pandas.core.frame.DataFrame'>\n",
            "RangeIndex: 248247 entries, 0 to 248246\n",
            "Data columns (total 10 columns):\n",
            " #   Column            Non-Null Count   Dtype \n",
            "---  ------            --------------   ----- \n",
            " 0   scene_id          248247 non-null  object\n",
            " 1   timestamp         248247 non-null  object\n",
            " 2   lat               248247 non-null  object\n",
            " 3   lon               248247 non-null  object\n",
            " 4   presence_score    248247 non-null  object\n",
            " 5   length_m          248247 non-null  object\n",
            " 6   mmsi              193266 non-null  object\n",
            " 7   matching_score    248247 non-null  object\n",
            " 8   fishing_score     248245 non-null  object\n",
            " 9   matched_category  248247 non-null  object\n",
            "dtypes: object(10)\n",
            "memory usage: 18.9+ MB\n",
            "None\n",
            "\n",
            "‚ùì Missing Values per Column:\n",
            "scene_id                0\n",
            "timestamp               0\n",
            "lat                     0\n",
            "lon                     0\n",
            "presence_score          0\n",
            "length_m                0\n",
            "mmsi                54981\n",
            "matching_score          0\n",
            "fishing_score           2\n",
            "matched_category        0\n",
            "dtype: int64\n",
            "\n",
            "üîÅ Number of Duplicate Rows:\n",
            "0\n",
            "\n",
            "üîç Initial checks for: sar_vessel_detections_pipev3_202412\n",
            "\n",
            "üìÑ Dataset Info:\n",
            "<class 'pandas.core.frame.DataFrame'>\n",
            "RangeIndex: 239081 entries, 0 to 239080\n",
            "Data columns (total 10 columns):\n",
            " #   Column            Non-Null Count   Dtype \n",
            "---  ------            --------------   ----- \n",
            " 0   scene_id          239081 non-null  object\n",
            " 1   timestamp         239081 non-null  object\n",
            " 2   lat               239081 non-null  object\n",
            " 3   lon               239081 non-null  object\n",
            " 4   presence_score    239081 non-null  object\n",
            " 5   length_m          239081 non-null  object\n",
            " 6   mmsi              188601 non-null  object\n",
            " 7   matching_score    239081 non-null  object\n",
            " 8   fishing_score     239077 non-null  object\n",
            " 9   matched_category  239081 non-null  object\n",
            "dtypes: object(10)\n",
            "memory usage: 18.2+ MB\n",
            "None\n",
            "\n",
            "‚ùì Missing Values per Column:\n",
            "scene_id                0\n",
            "timestamp               0\n",
            "lat                     0\n",
            "lon                     0\n",
            "presence_score          0\n",
            "length_m                0\n",
            "mmsi                50480\n",
            "matching_score          0\n",
            "fishing_score           4\n",
            "matched_category        0\n",
            "dtype: int64\n",
            "\n",
            "üîÅ Number of Duplicate Rows:\n",
            "0\n"
          ]
        }
      ],
      "source": [
        "# Loop through each loaded DataFrame in the dictionary\n",
        "for name, df in dataframes.items():\n",
        "    print(f\"\\nüîç Initial checks for: {name}\")\n",
        "\n",
        "    # Overview of the dataset\n",
        "    print(\"\\nüìÑ Dataset Info:\")\n",
        "    print(df.info())\n",
        "\n",
        "    # Count missing values per column\n",
        "    print(\"\\n‚ùì Missing Values per Column:\")\n",
        "    print(df.isnull().sum())\n",
        "\n",
        "    # Check for duplicates\n",
        "    print(\"\\nüîÅ Number of Duplicate Rows:\")\n",
        "    print(df.duplicated().sum())\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "c571d596-14c6-4fd6-b6bc-6b34954efad5",
      "metadata": {
        "id": "c571d596-14c6-4fd6-b6bc-6b34954efad5"
      },
      "source": [
        "**3. Merging Anchorages Datasets**\n",
        "\n",
        "The anchorage datasets were merged into a single DataFrame to facilitate unified analysis. This step combined multiple datasets related to anchorages, ensuring that all relevant data from different timeframes and sources is present in one dataset. This is an essential step for streamlining further data analysis and avoiding redundant information across multiple datasets."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "id": "3e0808ef-67f0-47ec-8d30-744c3de61f61",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3e0808ef-67f0-47ec-8d30-744c3de61f61",
        "outputId": "52ea793c-381b-462b-8b32-69a3f67f57fb"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Merging the following Anchorage datasets:\n",
            "- named_anchorages_v1_20191205\n",
            "- named_anchorages_v1_20181108\n",
            "- named_anchorages_v2_20201104\n",
            "- named_anchorages_v2_20221206\n",
            "\n",
            "Combined Anchorage dataset shape: (619253, 12)\n",
            "       s2id                  lat                 lon     label sublabel  \\\n",
            "0  3e4e429b   26.914042109356018   52.22031972443178   SHARJAH      NaN   \n",
            "1  1a575de7  -7.7159917314685496   11.72455952408813  BLOCK 17      NaN   \n",
            "2  3fcf5295    29.64207745041846   48.69670549586832  KAZ IRAQ      NaN   \n",
            "3  3fcf52bf   29.644147649617455  48.701872570021656  KAZ IRAQ      NaN   \n",
            "4  3fcf52bd   29.639744433742802  48.701768589783754  UMM QASR      NaN   \n",
            "\n",
            "      label_source iso3 distance_from_shore_m         drift_radius at_dock  \\\n",
            "0  top_destination  IRN                 63000  0.05632213051303668   FALSE   \n",
            "1  top_destination  AGO                134000   0.1111107365900863   FALSE   \n",
            "2  top_destination  KWT                 33000  0.16258325996472844   FALSE   \n",
            "3  top_destination  KWT                 33000  0.16162288669261704   FALSE   \n",
            "4  top_destination  KWT                 33000   0.1499641855732754   FALSE   \n",
            "\n",
            "  anchorage_group dock  \n",
            "0             NaN  NaN  \n",
            "1             NaN  NaN  \n",
            "2             NaN  NaN  \n",
            "3             NaN  NaN  \n",
            "4             NaN  NaN  \n"
          ]
        }
      ],
      "source": [
        "# 1. Merging the Anchorages datasets\n",
        "# Assuming the datasets have already been loaded into the `dataframes` dictionary\n",
        "\n",
        "# Select the anchorage datasets\n",
        "anchorage_keys = [key for key in dataframes.keys() if 'anchorages' in key]\n",
        "\n",
        "# Print the datasets being merged\n",
        "print(\"Merging the following Anchorage datasets:\")\n",
        "for key in anchorage_keys:\n",
        "    print(f\"- {key}\")\n",
        "\n",
        "# Merge them into a single DataFrame\n",
        "df_anchorages = pd.concat([dataframes[key] for key in anchorage_keys], ignore_index=True)\n",
        "\n",
        "# Display quick check\n",
        "print(\"\\nCombined Anchorage dataset shape:\", df_anchorages.shape)\n",
        "print(df_anchorages.head())\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "19ef14ca-e0a5-4ddf-83b8-5f82708e69b1",
      "metadata": {
        "id": "19ef14ca-e0a5-4ddf-83b8-5f82708e69b1"
      },
      "source": [
        "**4.Handling Missing Values Across Multiple Datasets**\n",
        "\n",
        "This step ensures that all loaded datasets are properly cleaned by addressing missing values. A loop iterates through each dataset, checking for columns with missing data. For numerical columns such as 'Length' and 'Width', missing values are filled using the median value. For categorical columns like 'Category', missing values are filled with the mode (most frequent value). If the mode is not available, missing categorical data is replaced with 'Unknown'. This approach ensures that missing data is handled consistently across all datasets, preventing errors by verifying the existence of each column before making changes. After cleaning, the missing value count is rechecked to confirm successful handling."
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import os\n",
        "\n",
        "# Optional: enable future behavior to avoid downcasting warning\n",
        "pd.set_option('future.no_silent_downcasting', True)\n",
        "\n",
        "# Paths\n",
        "raw_data_path = '/content/drive/MyDrive/yacht-data-insights/data/raw/'\n",
        "cleaned_data_path = '/content/drive/MyDrive/yacht-data-insights/data/cleaned/'\n",
        "\n",
        "# Ensure output folder exists\n",
        "os.makedirs(cleaned_data_path, exist_ok=True)\n",
        "\n",
        "# List CSV files\n",
        "csv_files = [file for file in os.listdir(raw_data_path) if file.endswith('.csv')]\n",
        "\n",
        "# Handle each dataset\n",
        "for file in csv_files:\n",
        "    file_path = os.path.join(raw_data_path, file)\n",
        "\n",
        "    try:\n",
        "        df = pd.read_csv(file_path, encoding='ISO-8859-1', low_memory=False)\n",
        "\n",
        "        # Report missing values before cleaning\n",
        "        missing_before = df.isnull().sum()\n",
        "        missing_before = missing_before[missing_before > 0]\n",
        "        if not missing_before.empty:\n",
        "            print(f\"\\nMissing values before cleaning in {file}:\\n{missing_before}\")\n",
        "        else:\n",
        "            print(f\"\\nNo missing values found in {file} before cleaning.\")\n",
        "\n",
        "        # Clean 'Length' and 'Width' if present and convert to numeric\n",
        "        for col in ['Length', 'Width']:\n",
        "            if col in df.columns:\n",
        "                df[col] = df[col].astype(str).str.extract(r'([\\d\\.]+)', expand=False)\n",
        "                df[col] = pd.to_numeric(df[col], errors='coerce')\n",
        "\n",
        "        # Fill missing values\n",
        "        for column in df.columns:\n",
        "            if df[column].isnull().sum() > 0:\n",
        "                if pd.api.types.is_numeric_dtype(df[column]):\n",
        "                    median_val = df[column].median()\n",
        "                    df[column] = df[column].fillna(median_val)\n",
        "                    print(f\"Filled missing values in numeric column '{column}' with median: {median_val}\")\n",
        "                else:\n",
        "                    mode_val = df[column].mode().dropna()\n",
        "                    if not mode_val.empty:\n",
        "                        df[column] = df[column].fillna(mode_val[0])\n",
        "                        print(f\"Filled missing values in categorical column '{column}' with mode: {mode_val[0]}\")\n",
        "                    else:\n",
        "                        df[column] = df[column].fillna('Unknown')\n",
        "                        print(f\"Filled missing values in categorical column '{column}' with 'Unknown'\")\n",
        "\n",
        "        # Ensure object types are converted properly (after fillna)\n",
        "        df = df.infer_objects(copy=False)\n",
        "\n",
        "        # Report missing values after cleaning\n",
        "        missing_after = df.isnull().sum()\n",
        "        missing_after = missing_after[missing_after > 0]\n",
        "        if not missing_after.empty:\n",
        "            print(f\"\\nMissing values after cleaning in {file}:\\n{missing_after}\")\n",
        "        else:\n",
        "            print(f\"\\nNo missing values left in {file} after cleaning.\")\n",
        "\n",
        "        # Save cleaned file\n",
        "        cleaned_file_path = os.path.join(cleaned_data_path, file)\n",
        "        df.to_csv(cleaned_file_path, index=False)\n",
        "        print(f\"Cleaned: {file}\")\n",
        "\n",
        "    except Exception as e:\n",
        "        print(f\"Failed to process {file}: {e}\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "50MLXAD4sSV8",
        "outputId": "4a62e5c7-8408-4c28-8744-3cca6ada4804"
      },
      "id": "50MLXAD4sSV8",
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Missing values before cleaning in named_anchorages_v1_20191205.csv:\n",
            "label                         6\n",
            "sublabel                 160922\n",
            "iso3                          7\n",
            "distance_from_shore_m        25\n",
            "drift_radius                162\n",
            "at_dock                       1\n",
            "dtype: int64\n",
            "Filled missing values in categorical column 'label' with mode: ZHOUSHAN\n",
            "Filled missing values in categorical column 'sublabel' with mode: FUJAIRAH OFFSHORE\n",
            "Filled missing values in categorical column 'iso3' with mode: CHN\n",
            "Filled missing values in numeric column 'distance_from_shore_m' with median: 1000.0\n",
            "Filled missing values in numeric column 'drift_radius' with median: 0.09844404256206604\n",
            "Filled missing values in categorical column 'at_dock' with mode: False\n",
            "\n",
            "No missing values left in named_anchorages_v1_20191205.csv after cleaning.\n",
            "Cleaned: named_anchorages_v1_20191205.csv\n",
            "\n",
            "No missing values found in CVP_loitering_202411.csv before cleaning.\n",
            "\n",
            "No missing values left in CVP_loitering_202411.csv after cleaning.\n",
            "Cleaned: CVP_loitering_202411.csv\n",
            "\n",
            "Missing values before cleaning in named_anchorages_v1_20181108.csv:\n",
            "label            2\n",
            "sublabel    115590\n",
            "iso3             7\n",
            "dtype: int64\n",
            "Filled missing values in categorical column 'label' with mode: SINGAPORE\n",
            "Filled missing values in categorical column 'sublabel' with mode: FUJAIRAH OFFSHORE\n",
            "Filled missing values in categorical column 'iso3' with mode: CHN\n",
            "\n",
            "No missing values left in named_anchorages_v1_20181108.csv after cleaning.\n",
            "Cleaned: named_anchorages_v1_20181108.csv\n",
            "\n",
            "No missing values found in Weather-for-Boating-Activities.csv before cleaning.\n",
            "\n",
            "No missing values left in Weather-for-Boating-Activities.csv after cleaning.\n",
            "Cleaned: Weather-for-Boating-Activities.csv\n",
            "\n",
            "No missing values found in CVP_ports_202411.csv before cleaning.\n",
            "\n",
            "No missing values left in CVP_ports_202411.csv after cleaning.\n",
            "Cleaned: CVP_ports_202411.csv\n",
            "\n",
            "Missing values before cleaning in boat_data.csv:\n",
            "Manufacturer    1338\n",
            "Type               6\n",
            "Length             9\n",
            "Width             56\n",
            "Material        1749\n",
            "Location          36\n",
            "dtype: int64\n",
            "Filled missing values in categorical column 'Manufacturer' with mode: B√É¬É√Ç¬©n√É¬É√Ç¬©teau power boats\n",
            "Filled missing values in categorical column 'Type' with mode: Used boat,Diesel\n",
            "Filled missing values in numeric column 'Length' with median: 10.28\n",
            "Filled missing values in numeric column 'Width' with median: 3.33\n",
            "Filled missing values in categorical column 'Material' with mode: GRP\n",
            "Filled missing values in categorical column 'Location' with mode: Netherlands √É¬Ç√Ç¬ª In verkoophaven\n",
            "\n",
            "No missing values left in boat_data.csv after cleaning.\n",
            "Cleaned: boat_data.csv\n",
            "\n",
            "No missing values found in CVP_encounters_202411.csv before cleaning.\n",
            "\n",
            "No missing values left in CVP_encounters_202411.csv after cleaning.\n",
            "Cleaned: CVP_encounters_202411.csv\n",
            "\n",
            "Missing values before cleaning in sar_vessel_detections_pipev20231026_202410.csv:\n",
            "mmsi             57265\n",
            "fishing_score        1\n",
            "dtype: int64\n",
            "Filled missing values in numeric column 'mmsi' with median: 412417808.5\n",
            "Filled missing values in numeric column 'fishing_score' with median: 0.484453\n",
            "\n",
            "No missing values left in sar_vessel_detections_pipev20231026_202410.csv after cleaning.\n",
            "Cleaned: sar_vessel_detections_pipev20231026_202410.csv\n",
            "\n",
            "Missing values before cleaning in named_anchorages_v2_20201104.csv:\n",
            "label                         6\n",
            "sublabel                 160919\n",
            "iso3                          7\n",
            "distance_from_shore_m        25\n",
            "drift_radius                169\n",
            "at_dock                      35\n",
            "dtype: int64\n",
            "Filled missing values in categorical column 'label' with mode: ZHOUSHAN\n",
            "Filled missing values in categorical column 'sublabel' with mode: FUJAIRAH OFFSHORE\n",
            "Filled missing values in categorical column 'iso3' with mode: CHN\n",
            "Filled missing values in numeric column 'distance_from_shore_m' with median: 1000.0\n",
            "Filled missing values in numeric column 'drift_radius' with median: 0.09844404256206604\n",
            "Filled missing values in categorical column 'at_dock' with mode: False\n",
            "\n",
            "No missing values left in named_anchorages_v2_20201104.csv after cleaning.\n",
            "Cleaned: named_anchorages_v2_20201104.csv\n",
            "\n",
            "Missing values before cleaning in boat_dataset.csv:\n",
            "Manufacturer                   1390\n",
            "Model                             3\n",
            "Boat name                      9031\n",
            "Type                              5\n",
            "Year Built                      567\n",
            "Condition                      6969\n",
            "Length                           10\n",
            "Width                            63\n",
            "Depth                          3110\n",
            "Displacement                   5293\n",
            "CE Design Category             9562\n",
            "Cert Number of People          6747\n",
            "Number of Cabins               3869\n",
            "Number of beds                 3937\n",
            "Hull Color                     7033\n",
            "Number of Toilets              8188\n",
            "Number of Bathrooms            9881\n",
            "Number of Showers              8403\n",
            "Material                       1832\n",
            "Fresh Water Cap                8226\n",
            "Holding Tank                   9525\n",
            "Propulsion                     7053\n",
            "Engine                          809\n",
            "Engine Performance             2281\n",
            "Fuel Capacity                  3530\n",
            "Fuel Type                      2322\n",
            "Engine Hours                   5211\n",
            "Max Speed                      9452\n",
            "Cruising Speed                 9797\n",
            "Location                         43\n",
            "Advertisement Date             9474\n",
            "Number of views last 7 days     363\n",
            "Comments                       3266\n",
            "Additional Comments            7890\n",
            "Equipment                      4170\n",
            "dtype: int64\n",
            "Filled missing values in categorical column 'Manufacturer' with mode: B√É¬©n√É¬©teau power boats\n",
            "Filled missing values in categorical column 'Model' with mode: BARRACUDA 8\n",
            "Filled missing values in categorical column 'Boat name' with mode: Maxima\n",
            "Filled missing values in categorical column 'Type' with mode: Used boat,Diesel\n",
            "Filled missing values in numeric column 'Year Built' with median: 2008.0\n",
            "Filled missing values in categorical column 'Condition' with mode: very good\n",
            "Filled missing values in numeric column 'Length' with median: 10.2\n",
            "Filled missing values in numeric column 'Width' with median: 3.3\n",
            "Filled missing values in categorical column 'Depth' with mode: 0.90 m\n",
            "Filled missing values in categorical column 'Displacement' with mode: 12000 kg\n",
            "Filled missing values in categorical column 'CE Design Category' with mode: C - Inshore\n",
            "Filled missing values in numeric column 'Cert Number of People' with median: 8.0\n",
            "Filled missing values in numeric column 'Number of Cabins' with median: 2.0\n",
            "Filled missing values in numeric column 'Number of beds' with median: 4.0\n",
            "Filled missing values in categorical column 'Hull Color' with mode: white white\n",
            "Filled missing values in numeric column 'Number of Toilets' with median: 1.0\n",
            "Filled missing values in numeric column 'Number of Bathrooms' with median: 1.0\n",
            "Filled missing values in numeric column 'Number of Showers' with median: 1.0\n",
            "Filled missing values in categorical column 'Material' with mode: GRP\n",
            "Filled missing values in categorical column 'Fresh Water Cap' with mode: 100 l\n",
            "Filled missing values in categorical column 'Holding Tank' with mode: 100 l\n",
            "Filled missing values in categorical column 'Propulsion' with mode: Inboard with Shaft\n",
            "Filled missing values in categorical column 'Engine' with mode: Volvo Penta\n",
            "Filled missing values in categorical column 'Engine Performance' with mode: 1 x 200 HP / 147 kW\n",
            "Filled missing values in categorical column 'Fuel Capacity' with mode: 400 l\n",
            "Filled missing values in categorical column 'Fuel Type' with mode: Diesel\n",
            "Filled missing values in categorical column 'Engine Hours' with mode: 500 h\n",
            "Filled missing values in categorical column 'Max Speed' with mode: 30 knots\n",
            "Filled missing values in categorical column 'Cruising Speed' with mode: 25 knots\n",
            "Filled missing values in categorical column 'Location' with mode: Netherlands √Ç¬ª In verkoophaven\n",
            "Filled missing values in categorical column 'Advertisement Date' with mode: 14.07.2020\n",
            "Filled missing values in categorical column 'Number of views last 7 days' with mode: 68\n",
            "Filled missing values in categorical column 'Comments' with mode: Wir sprechen Deutsch. Vermittlungsprovision nicht inbegriffen.\n",
            "Filled missing values in categorical column 'Additional Comments' with mode: Ex-works price,Not included:,- Motor,- Options,- CH delivery and approval,,Preis ab Werk:,Nicht inklusive:,- Motor,- Optionen,- Lieferung und Homologation\n",
            "Filled missing values in categorical column 'Equipment' with mode: Battery\n",
            "\n",
            "No missing values left in boat_dataset.csv after cleaning.\n",
            "Cleaned: boat_dataset.csv\n",
            "\n",
            "Missing values before cleaning in Boats_No_Price_dataset.csv:\n",
            "beam_ft            51\n",
            "dryWeight_lb      320\n",
            "fuelType           51\n",
            "totalHP           119\n",
            "maxEngineYear     583\n",
            "minEngineYear     586\n",
            "engineCategory    231\n",
            "price             936\n",
            "city               15\n",
            "state              15\n",
            "zip                81\n",
            "dtype: int64\n",
            "Filled missing values in numeric column 'beam_ft' with median: 8.5\n",
            "Filled missing values in numeric column 'dryWeight_lb' with median: 3302.5\n",
            "Filled missing values in categorical column 'fuelType' with mode: gasoline\n",
            "Filled missing values in numeric column 'totalHP' with median: 150.0\n",
            "Filled missing values in numeric column 'maxEngineYear' with median: 2019.0\n",
            "Filled missing values in numeric column 'minEngineYear' with median: 2019.0\n",
            "Filled missing values in categorical column 'engineCategory' with mode: outboard\n",
            "Filled missing values in numeric column 'price' with median: nan\n",
            "Filled missing values in categorical column 'city' with mode: Counce\n",
            "Filled missing values in categorical column 'state' with mode: FL\n",
            "Filled missing values in numeric column 'zip' with median: 33543.0\n",
            "\n",
            "Missing values after cleaning in Boats_No_Price_dataset.csv:\n",
            "price    936\n",
            "dtype: int64\n",
            "Cleaned: Boats_No_Price_dataset.csv\n",
            "\n",
            "Missing values before cleaning in named_anchorages_v2_20221206.csv:\n",
            "sublabel                 6284\n",
            "distance_from_shore_m      25\n",
            "drift_radius              153\n",
            "dock                       20\n",
            "dtype: int64\n",
            "Filled missing values in categorical column 'sublabel' with mode: ZHOUSHAN\n",
            "Filled missing values in numeric column 'distance_from_shore_m' with median: 1000.0\n",
            "Filled missing values in numeric column 'drift_radius' with median: 0.0984470175062132\n",
            "Filled missing values in categorical column 'dock' with mode: False\n",
            "\n",
            "No missing values left in named_anchorages_v2_20221206.csv after cleaning.\n",
            "Cleaned: named_anchorages_v2_20221206.csv\n",
            "\n",
            "Missing values before cleaning in sar_vessel_detections_pipev3_202411.csv:\n",
            "mmsi             54981\n",
            "fishing_score        2\n",
            "dtype: int64\n",
            "Filled missing values in numeric column 'mmsi' with median: 412435155.0\n",
            "Filled missing values in numeric column 'fishing_score' with median: 0.4614315\n",
            "\n",
            "No missing values left in sar_vessel_detections_pipev3_202411.csv after cleaning.\n",
            "Cleaned: sar_vessel_detections_pipev3_202411.csv\n",
            "\n",
            "Missing values before cleaning in sar_vessel_detections_pipev3_202412.csv:\n",
            "mmsi             50480\n",
            "fishing_score        4\n",
            "dtype: int64\n",
            "Filled missing values in numeric column 'mmsi' with median: 412470862.0\n",
            "Filled missing values in numeric column 'fishing_score' with median: 0.3416485\n",
            "\n",
            "No missing values left in sar_vessel_detections_pipev3_202412.csv after cleaning.\n",
            "Cleaned: sar_vessel_detections_pipev3_202412.csv\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "id": "c331bd89-d996-45de-8a29-bdde2b724737",
      "metadata": {
        "id": "c331bd89-d996-45de-8a29-bdde2b724737"
      },
      "source": [
        "**5. Removing Duplicates and Cleaning Data Types**\n",
        "\n",
        "This step removes duplicate rows to ensure the dataset contains unique entries. Afterward, it verifies that each column has the correct data type, converting numerical columns to numeric types, categorical columns to categories, and date columns to datetime format. This ensures data consistency and prepares the dataset for accurate analysis and modeling.\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Handle duplicates\n",
        "for file in csv_files:\n",
        "    file_path = os.path.join(raw_data_path, file)\n",
        "\n",
        "    try:\n",
        "        df = pd.read_csv(file_path, encoding='ISO-8859-1', low_memory=False)\n",
        "\n",
        "        # Remove duplicates\n",
        "        df = df.drop_duplicates()\n",
        "        print(f\"Removed duplicate rows in {file}. New row count: {len(df)}\")\n",
        "\n",
        "        # Check and convert data types after cleaning\n",
        "        # Example for converting specific columns to the correct type\n",
        "        if 'Date' in df.columns:\n",
        "            df['Date'] = pd.to_datetime(df['Date'], errors='coerce')  # Convert 'Date' column to datetime\n",
        "        if 'Category' in df.columns:\n",
        "            df['Category'] = df['Category'].astype('category')  # Convert 'Category' column to category type\n",
        "\n",
        "        # Optionally, you can also convert numeric columns explicitly\n",
        "        for col in ['Length', 'Width']:  # Example for numerical columns\n",
        "            if col in df.columns:\n",
        "                df[col] = pd.to_numeric(df[col], errors='coerce')\n",
        "\n",
        "        # Save the cleaned data after removing duplicates and adjusting data types\n",
        "        cleaned_file_path = os.path.join(cleaned_data_path, file)\n",
        "        df.to_csv(cleaned_file_path, index=False)\n",
        "        print(f\"Cleaned and processed {file} (duplicates removed and data types adjusted)\")\n",
        "\n",
        "    except Exception as e:\n",
        "        print(f\"Failed to process {file}: {e}\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_knvSSAS4yz7",
        "outputId": "803f60bc-fe33-4244-c05d-8165b767d51f"
      },
      "id": "_knvSSAS4yz7",
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Removed duplicate rows in named_anchorages_v1_20191205.csv. New row count: 166508\n",
            "Cleaned and processed named_anchorages_v1_20191205.csv (duplicates removed and data types adjusted)\n",
            "Removed duplicate rows in CVP_loitering_202411.csv. New row count: 684\n",
            "Cleaned and processed CVP_loitering_202411.csv (duplicates removed and data types adjusted)\n",
            "Removed duplicate rows in named_anchorages_v1_20181108.csv. New row count: 119748\n",
            "Cleaned and processed named_anchorages_v1_20181108.csv (duplicates removed and data types adjusted)\n",
            "Removed duplicate rows in Weather-for-Boating-Activities.csv. New row count: 125\n",
            "Cleaned and processed Weather-for-Boating-Activities.csv (duplicates removed and data types adjusted)\n",
            "Removed duplicate rows in CVP_ports_202411.csv. New row count: 1410\n",
            "Cleaned and processed CVP_ports_202411.csv (duplicates removed and data types adjusted)\n",
            "Removed duplicate rows in boat_data.csv. New row count: 9888\n",
            "Cleaned and processed boat_data.csv (duplicates removed and data types adjusted)\n",
            "Removed duplicate rows in CVP_encounters_202411.csv. New row count: 348\n",
            "Cleaned and processed CVP_encounters_202411.csv (duplicates removed and data types adjusted)\n",
            "Removed duplicate rows in sar_vessel_detections_pipev20231026_202410.csv. New row count: 268681\n",
            "Cleaned and processed sar_vessel_detections_pipev20231026_202410.csv (duplicates removed and data types adjusted)\n",
            "Removed duplicate rows in named_anchorages_v2_20201104.csv. New row count: 166515\n",
            "Cleaned and processed named_anchorages_v2_20201104.csv (duplicates removed and data types adjusted)\n",
            "Removed duplicate rows in boat_dataset.csv. New row count: 10343\n",
            "Cleaned and processed boat_dataset.csv (duplicates removed and data types adjusted)\n",
            "Removed duplicate rows in Boats_No_Price_dataset.csv. New row count: 936\n",
            "Cleaned and processed Boats_No_Price_dataset.csv (duplicates removed and data types adjusted)\n",
            "Removed duplicate rows in named_anchorages_v2_20221206.csv. New row count: 166482\n",
            "Cleaned and processed named_anchorages_v2_20221206.csv (duplicates removed and data types adjusted)\n",
            "Removed duplicate rows in sar_vessel_detections_pipev3_202411.csv. New row count: 248247\n",
            "Cleaned and processed sar_vessel_detections_pipev3_202411.csv (duplicates removed and data types adjusted)\n",
            "Removed duplicate rows in sar_vessel_detections_pipev3_202412.csv. New row count: 239081\n",
            "Cleaned and processed sar_vessel_detections_pipev3_202412.csv (duplicates removed and data types adjusted)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "id": "be9b48fe-f4eb-4c49-8344-2611dd53d118",
      "metadata": {
        "id": "be9b48fe-f4eb-4c49-8344-2611dd53d118"
      },
      "source": [
        "**6. Ensuring Target Availability and Encoding Categorical Variables**\n",
        "\n",
        "After performing an initial cleaning check on the datasets by inspecting columns before and after cleaning, I noticed that some important target variables were missing‚Äîspecifically, the Price column from the boat sales data and relevant maintenance data.\n",
        "\n",
        "For maintenance, the original raw datasets (SAR vessel detections and loitering events) were reloaded. Rather than applying extensive cleaning, I selected a subset of relevant columns from each and merged them on vessel_id to create a combined maintenance-ready dataset.\n",
        "\n",
        "For price prediction, since the Price column had been lost during initial cleaning, I reloaded the original boat dataset. I cleaned the Price column by converting it to numeric and filling missing values, and then applied one-hot encoding to categorical variables to prepare independent and dependent variables for modeling.\n",
        "\n",
        "For route optimization, I standardized the latitude and longitude features and applied KMeans clustering. This produced cluster labels, which were added as a new feature to support further route analysis and optimization.\n",
        "\n",
        "Finally, I integrated a weather dataset relevant to boating activities. After loading the file using the appropriate encoding to handle character issues, I selected core features such as wind speed, wave height, and overall weather conditions. Categorical variables such as Weather, Day of the Week, and Boat Technical Condition were encoded using label encoding, and the target variable (Decision) was also encoded to prepare the dataset for classification modeling. This completed the encoding phase and ensured all datasets were target-ready and suitable for the next steps in the machine learning workflow."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "id": "52b6e2b0-8854-484a-b897-acd0b0d0af40",
      "metadata": {
        "id": "52b6e2b0-8854-484a-b897-acd0b0d0af40",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "1ba1ca91-c78e-4725-901e-12ea7e10b457"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Columns before cleaning:\n",
            "Index(['scene_id', 'timestamp', 'lat', 'lon', 'presence_score', 'length_m',\n",
            "       'mmsi', 'matching_score', 'fishing_score', 'matched_category'],\n",
            "      dtype='object')\n",
            "Columns after cleaning:\n",
            "Index(['scene_id', 'timestamp', 'lat', 'lon', 'presence_score', 'length_m',\n",
            "       'mmsi', 'matching_score', 'fishing_score', 'matched_category'],\n",
            "      dtype='object')\n"
          ]
        }
      ],
      "source": [
        "# Before cleaning\n",
        "print(\"Columns before cleaning:\")\n",
        "print(df.columns)\n",
        "\n",
        "# After cleaning\n",
        "print(\"Columns after cleaning:\")\n",
        "print(df.columns)\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "\n",
        "# Load datasets\n",
        "raw_data_path = '/content/drive/MyDrive/yacht-data-insights/data/raw/'\n",
        "\n",
        "df_sar = pd.read_csv(f'{raw_data_path}sar_vessel_detections_pipev3_202412.csv', encoding='ISO-8859-1')\n",
        "df_loiter = pd.read_csv(f'{raw_data_path}CVP_loitering_202411.csv', encoding='ISO-8859-1')\n",
        "\n",
        "# Display columns for sanity check\n",
        "print(\"SAR columns:\", df_sar.columns)\n",
        "print(\"Loitering columns:\", df_loiter.columns)\n",
        "\n",
        "# Select relevant columns\n",
        "sar_cols_to_use = ['mmsi', 'presence_score', 'length_m', 'matching_score', 'fishing_score', 'matched_category']\n",
        "loiter_cols_to_use = ['vessel_id', 'event_type', 'event_start', 'event_end', 'lat_mean', 'lon_mean']\n",
        "\n",
        "df_sar_reduced = df_sar[sar_cols_to_use].copy()\n",
        "df_loiter_reduced = df_loiter[loiter_cols_to_use].copy()\n",
        "\n",
        "# Rename for clarity & consistency before merge\n",
        "df_sar_reduced.rename(columns={'mmsi': 'vessel_id'}, inplace=True)\n",
        "\n",
        "# Convert vessel_id columns to string type in both DataFrames to avoid merge errors\n",
        "df_sar_reduced['vessel_id'] = df_sar_reduced['vessel_id'].astype(str)\n",
        "df_loiter_reduced['vessel_id'] = df_loiter_reduced['vessel_id'].astype(str)\n",
        "\n",
        "# Merge datasets on 'vessel_id' with outer join\n",
        "df_maintenance_ready = pd.merge(df_sar_reduced, df_loiter_reduced, on='vessel_id', how='outer')\n",
        "\n",
        "# Check the merged data\n",
        "print(\"Merged dataset shape:\", df_maintenance_ready.shape)\n",
        "print(df_maintenance_ready.head())\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4fzgpxfHeblm",
        "outputId": "7c99252a-df83-4f6b-e227-096ddc0d4178"
      },
      "id": "4fzgpxfHeblm",
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "SAR columns: Index(['scene_id', 'timestamp', 'lat', 'lon', 'presence_score', 'length_m',\n",
            "       'mmsi', 'matching_score', 'fishing_score', 'matched_category'],\n",
            "      dtype='object')\n",
            "Loitering columns: Index(['event_id', 'event_type', 'vessel_id', 'event_start', 'event_end',\n",
            "       'lat_mean', 'lon_mean', 'lat_min', 'lat_max', 'lon_min', 'lon_max',\n",
            "       'event_info', 'event_vessels', 'event_geography'],\n",
            "      dtype='object')\n",
            "Merged dataset shape: (239765, 11)\n",
            "  vessel_id  presence_score    length_m  matching_score  fishing_score  \\\n",
            "0       0.0        0.999211   28.513245        0.317074       0.804592   \n",
            "1       0.0        0.998853   42.291348        0.226967       0.723040   \n",
            "2       0.0        0.999838   19.994408        0.015303       0.941307   \n",
            "3       0.0        0.983325   20.038578       10.793140       0.960768   \n",
            "4       0.0        0.997541  168.448975        9.604926       0.012883   \n",
            "\n",
            "  matched_category event_type event_start event_end  lat_mean  lon_mean  \n",
            "0     noisy_vessel        NaN         NaN       NaN       NaN       NaN  \n",
            "1     noisy_vessel        NaN         NaN       NaN       NaN       NaN  \n",
            "2     noisy_vessel        NaN         NaN       NaN       NaN       NaN  \n",
            "3     noisy_vessel        NaN         NaN       NaN       NaN       NaN  \n",
            "4     noisy_vessel        NaN         NaN       NaN       NaN       NaN  \n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "\n",
        "# Path to the raw data folder\n",
        "raw_data_path = '/content/drive/MyDrive/yacht-data-insights/data/raw/'\n",
        "\n",
        "# Reload the raw boat dataset with the proper encoding to avoid 'UnicodeDecodeError'\n",
        "df_boat = pd.read_csv(f'{raw_data_path}boat_dataset.csv', encoding='ISO-8859-1')\n",
        "\n",
        "# Check the columns to verify the dataset\n",
        "print(\"Columns in boat dataset:\", df_boat.columns)\n",
        "\n",
        "# Clean and preprocess the 'Price' column if present\n",
        "if 'Price' in df_boat.columns:\n",
        "    # If Price column contains non-numeric values (e.g., 'N/A', '$', etc.), convert them to numeric\n",
        "    df_boat['Price'] = pd.to_numeric(df_boat['Price'], errors='coerce')\n",
        "\n",
        "    # Handle missing prices by filling with the median value\n",
        "    df_boat['Price'] = df_boat['Price'].fillna(df_boat['Price'].median())\n",
        "\n",
        "# Encoding categorical variables\n",
        "# Check if any categorical columns need encoding\n",
        "categorical_columns = df_boat.select_dtypes(include=['object']).columns\n",
        "\n",
        "# Perform one-hot encoding on categorical variables\n",
        "df_boat_encoded = pd.get_dummies(df_boat, columns=categorical_columns, drop_first=True)\n",
        "\n",
        "# Define your independent variables (X) and dependent variable (y)\n",
        "X = df_boat_encoded.drop(columns=['Price'])  # Drop Price if it's the dependent variable\n",
        "y = df_boat_encoded['Price']  # Assuming Price is the target for prediction\n",
        "\n",
        "# Check the shape of the final datasets\n",
        "print(\"Shape of the independent variables (X):\", X.shape)\n",
        "print(\"Shape of the dependent variable (y):\", y.shape)\n",
        "\n",
        "# Now you can proceed with model training or further analysis\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "UGiZe47sefLk",
        "outputId": "b0fdb5e0-a8a3-4271-9113-f7195bc4fb8e"
      },
      "id": "UGiZe47sefLk",
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Columns in boat dataset: Index(['Price', 'Category', 'Boat Type', 'Manufacturer', 'Model', 'Boat name',\n",
            "       'Type', 'Year Built', 'Condition', 'Length', 'Width', 'Depth',\n",
            "       'Displacement', 'CE Design Category', 'Cert Number of People',\n",
            "       'Number of Cabins', 'Number of beds', 'Hull Color', 'Number of Toilets',\n",
            "       'Number of Bathrooms', 'Number of Showers', 'Material',\n",
            "       'Fresh Water Cap', 'Holding Tank', 'Propulsion', 'Engine',\n",
            "       'Engine Performance', 'Fuel Capacity', 'Fuel Type', 'Engine Hours',\n",
            "       'Max Speed', 'Cruising Speed', 'Location', 'Advertisement Date',\n",
            "       'Number of views last 7 days', 'Comments', 'Additional Comments',\n",
            "       'Equipment'],\n",
            "      dtype='object')\n",
            "Shape of the independent variables (X): (10344, 40219)\n",
            "Shape of the dependent variable (y): (10344,)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Route Optimization (Clustering)\n",
        "route_features = ['lat', 'lon']\n",
        "\n",
        "if all(col in df.columns for col in route_features):\n",
        "    X_route = df[route_features].dropna()\n",
        "\n",
        "    from sklearn.preprocessing import StandardScaler\n",
        "    X_route_scaled = StandardScaler().fit_transform(X_route)\n",
        "\n",
        "    from sklearn.cluster import KMeans\n",
        "    kmeans = KMeans(n_clusters=5, random_state=42)\n",
        "    df['route_cluster'] = kmeans.fit_predict(X_route_scaled)\n",
        "\n",
        "    print(\"üß≠ Route Optimization\")\n",
        "    print(f\"Route clusters assigned. Sample:\\n{df[['lat', 'lon', 'route_cluster']].head()}\")\n",
        "else:\n",
        "    print(\"Required GPS features not found.\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "QhEZWPjoe9z5",
        "outputId": "7aca8c66-0e8a-4bb1-dcef-991d8b0674cf"
      },
      "id": "QhEZWPjoe9z5",
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "üß≠ Route Optimization\n",
            "Route clusters assigned. Sample:\n",
            "         lat         lon  route_cluster\n",
            "0  39.806985   25.831447              2\n",
            "1  58.653740   21.553987              2\n",
            "2   4.247573  119.633861              4\n",
            "3   1.156218  119.212269              4\n",
            "4   0.015330  117.588380              4\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "import pandas as pd\n",
        "from sklearn.preprocessing import LabelEncoder\n",
        "\n",
        "# Mount Google Drive\n",
        "drive.mount('/content/drive')\n",
        "\n",
        "# Path to the weather dataset\n",
        "weather_path = '/content/drive/MyDrive/yacht-data-insights/data/raw/Weather-for-Boating-Activities.csv'\n",
        "\n",
        "# Load the weather dataset with utf-8-sig encoding to handle BOM characters\n",
        "df_weather = pd.read_csv(weather_path, encoding='utf-8-sig')\n",
        "\n",
        "# Display columns for sanity check\n",
        "print(\"Weather dataset columns:\", df_weather.columns)\n",
        "\n",
        "# Select relevant columns (adjust these as per your actual columns)\n",
        "weather_cols_to_use = ['Wind Speed', 'Wave Height', 'Weather', 'Day of the Week', 'Boat Technical Condition', 'Decision']\n",
        "\n",
        "df_weather_reduced = df_weather[weather_cols_to_use].copy()\n",
        "\n",
        "# Check for missing values (optional)\n",
        "print(\"Missing values per column:\\n\", df_weather_reduced.isnull().sum())\n",
        "\n",
        "# Handle missing values if needed (example: fill with mode or drop)\n",
        "df_weather_reduced = df_weather_reduced.dropna()\n",
        "\n",
        "# Encode categorical variables\n",
        "le_weather = LabelEncoder()\n",
        "le_day = LabelEncoder()\n",
        "le_boat_cond = LabelEncoder()\n",
        "le_decision = LabelEncoder()\n",
        "\n",
        "df_weather_reduced['Weather'] = le_weather.fit_transform(df_weather_reduced['Weather'])\n",
        "df_weather_reduced['Day of the Week'] = le_day.fit_transform(df_weather_reduced['Day of the Week'])\n",
        "df_weather_reduced['Boat Technical Condition'] = le_boat_cond.fit_transform(df_weather_reduced['Boat Technical Condition'])\n",
        "df_weather_reduced['Decision'] = le_decision.fit_transform(df_weather_reduced['Decision'])\n",
        "\n",
        "# Define independent variables X and dependent variable y\n",
        "X = df_weather_reduced.drop('Decision', axis=1)\n",
        "y = df_weather_reduced['Decision']\n",
        "\n",
        "print(\"Encoded dataset preview:\")\n",
        "print(df_weather_reduced.head())\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "HZorFeqgsXot",
        "outputId": "9d000443-64b7-4153-975c-85f178ba73fb"
      },
      "id": "HZorFeqgsXot",
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n",
            "Weather dataset columns: Index(['Wind Speed', 'Wave Height', 'Weather', 'Day of the Week',\n",
            "       'Boat Technical Condition', 'Decision'],\n",
            "      dtype='object')\n",
            "Missing values per column:\n",
            " Wind Speed                  0\n",
            "Wave Height                 0\n",
            "Weather                     0\n",
            "Day of the Week             0\n",
            "Boat Technical Condition    0\n",
            "Decision                    0\n",
            "dtype: int64\n",
            "Encoded dataset preview:\n",
            "  Wind Speed Wave Height  Weather  Day of the Week  Boat Technical Condition  \\\n",
            "0        Low         Low        0                0                         2   \n",
            "1     Medium        High        2                0                         2   \n",
            "2        Low        High        2                0                         2   \n",
            "3     Medium         Low        2                0                         2   \n",
            "4     Medium        High        2                1                         1   \n",
            "\n",
            "   Decision  \n",
            "0         0  \n",
            "1         0  \n",
            "2         0  \n",
            "3         0  \n",
            "4         0  \n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "id": "5bf51003-4de7-4265-b3e6-d883ae0820b7",
      "metadata": {
        "id": "5bf51003-4de7-4265-b3e6-d883ae0820b7"
      },
      "source": [
        "7. Scale Numerical Features\n",
        "Numerical features were scaled using StandardScaler to ensure all features contribute equally to model performance."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "f87b7108-3446-411a-8ebc-642c2b2e6a45",
      "metadata": {
        "id": "f87b7108-3446-411a-8ebc-642c2b2e6a45"
      },
      "outputs": [],
      "source": [
        "from sklearn.preprocessing import StandardScaler\n",
        "\n",
        "# Apply standard scaling\n",
        "scaler = StandardScaler()\n",
        "df[['numerical_column1', 'numerical_column2']] = scaler.fit_transform(df[['numerical_column1', 'numerical_column2']])"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "f8afe38b-f366-42ca-b011-d56d24454997",
      "metadata": {
        "id": "f8afe38b-f366-42ca-b011-d56d24454997"
      },
      "source": [
        "8. Split Dataset into Train/Test\n",
        "The cleaned and prepared dataset was split into training and testing sets to allow model validation on unseen data."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "38f255ce-c742-49f3-a7af-a36c3ce471cb",
      "metadata": {
        "id": "38f255ce-c742-49f3-a7af-a36c3ce471cb"
      },
      "outputs": [],
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "# Separate features and target\n",
        "X = df.drop('target_column', axis=1)\n",
        "y = df['target_column']\n",
        "\n",
        "# Create training and testing sets\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3 (ipykernel)",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.13.1"
    },
    "colab": {
      "provenance": []
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}